{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1562a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import torch.optim as optim\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57302e2",
   "metadata": {},
   "source": [
    "# Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6308cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_utils_pomo import get_metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7ae70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "metrics = get_metrics(cur_path)\n",
    "os.chdir('./Reward_weights')\n",
    "for m in metrics:\n",
    "\n",
    "    dic_tarif_sent_disp = {'v_required': 0,\n",
    "                    'v_sent': 0,\n",
    "                    'v_sent_full':0,\n",
    "                    'v_degraded':0,\n",
    "                    'cancelled':0, #cancel departure\n",
    "                    'function_not_found':0,\n",
    "                    'v1_not_sent_from_s1':0,\n",
    "                    'v3_not_sent_from_s3':0,\n",
    "                    'v_not_found_in_last_station':0,\n",
    "                    'ff_required':0,\n",
    "                    'ff_sent':0,\n",
    "                    'rupture_ff':0,       \n",
    "                    'z1_VSAV_sent': 0,\n",
    "                    'z1_FPT_sent': 0,\n",
    "                    'z1_EPA_sent': 0,\n",
    "                     'VSAV_needed':0,\n",
    "                     'FPT_needed':0,\n",
    "                     'EPA_needed':0,\n",
    "                     'VSAV_disp':0,\n",
    "                     'FPT_disp':0,\n",
    "                     'EPA_disp':0,\n",
    "                    'skill_lvl':0\n",
    "                    } \n",
    "\n",
    "    dic_tarif_sent_disp[m] = -100\n",
    "\n",
    "    if m == 'v_degraded':\n",
    "        \n",
    "        dic_tarif_sent_disp['v_sent_full'] = 10\n",
    "\n",
    "\n",
    "    with open(f\"rw_\"+ m +\"_r100_cf3.json\", \"w\") as f:\n",
    "        json.dump(dic_tarif_sent_disp, f)\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22feeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_sent': 0,\n",
       " 'v_sent_full': 0,\n",
       " 'v_degraded': 0,\n",
       " 'cancelled': 0,\n",
       " 'function_not_found': 0,\n",
       " 'v1_not_sent_from_1st_station': -100,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'z1_sent': 0,\n",
       " 'skill_lvl': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v1_not_sent_from_1st_station\"\n",
    "with open(f\"rw_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6b63d",
   "metadata": {},
   "source": [
    "# Agent params POMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[0.93103448 1.         0.88888889 ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    file_path = f\"Reward_weights/rw_pomo_agent_{metric}_r100_cf3.json\"\n",
    "    try: os.remove(file_path)\n",
    "    except FileNotFoundError: print(f\"File '{file_path}' not found.\")\n",
    "print()\n",
    "\n",
    "#-------Start\n",
    "intervalle = 40\n",
    "start = 1\n",
    "\n",
    "while start <= 53080:\n",
    "    \n",
    "    end = start + intervalle - 1\n",
    "    if end > 53080: end = 53080\n",
    "    cmd = [\"python3\", \"-u\", \"agent_pomo_run.py\", \"--start\", str(start), \"--end\", str(end)]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        line_count += 1\n",
    "        #if line_count % 100 == 0:\n",
    "           #clear_output(wait=True)\n",
    "\n",
    "        print(line.strip())\n",
    "    \n",
    "    process.wait()\n",
    "    \n",
    "    start += intervalle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c50c41",
   "metadata": {},
   "source": [
    "I copy-pasted the output of previous block in the log.txt file so we can load this ipynb file in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[1.         1.         0.85185185 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.125      0.         0.5        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47fd99",
   "metadata": {},
   "source": [
    "# Reward  obtenu apr√®s it√©ration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c4f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_required': 55,\n",
       " 'v_sent': 56,\n",
       " 'v_sent_full': 55,\n",
       " 'v_degraded': 1,\n",
       " 'rupture_ff': 6,\n",
       " 'function_not_found': 5,\n",
       " 'v1_not_sent_from_s1': 11,\n",
       " 'v3_not_sent_from_s3': 0,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'ff_required': 0,\n",
       " 'ff_sent': 200,\n",
       " 'z1_VSAV_sent': 0,\n",
       " 'z1_FPT_sent': 0,\n",
       " 'z1_EPA_sent': 0,\n",
       " 'VSAV_needed': 0,\n",
       " 'FPT_needed': 0,\n",
       " 'EPA_needed': 0,\n",
       " 'VSAV_disp': 8,\n",
       " 'FPT_disp': 0,\n",
       " 'EPA_disp': 0,\n",
       " 'skill_lvl': 331.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4244a",
   "metadata": {},
   "source": [
    "# Reward Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc623ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682.99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_mean_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875ee5e",
   "metadata": {},
   "source": [
    "# NEW version POMO test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Avg reward: 39.7859\n",
      "Epoch 50, Avg reward: 41.7350\n",
      "Epoch 100, Avg reward: 52.0276\n",
      "Epoch 150, Avg reward: 50.0130\n"
     ]
    }
   ],
   "source": [
    "from agent import POMO_Agent\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def generate_instances(batch_size, n_nodes, device):\n",
    "    return torch.rand(batch_size, n_nodes, 2, device=device)\n",
    "\n",
    "def compute_tour_length(coords, tours):\n",
    "    B, P, N = tours.size()\n",
    "    tour_coords = torch.gather(coords.unsqueeze(1).expand(-1, P, -1, -1), 2, tours.unsqueeze(-1).expand(-1, -1, -1, 2))\n",
    "    rolled = torch.roll(tour_coords, shifts=-1, dims=2)\n",
    "    lengths = ((tour_coords - rolled) ** 2).sum(dim=-1).sqrt().sum(dim=-1)\n",
    "    return lengths\n",
    "\n",
    "N_EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "N_NODES = 80\n",
    "POMO_SIZE = 2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hyper_params = {\n",
    "    \"node_feature_size\": 2,  # (x,y)\n",
    "    \"hidden_size\": 64,      # Taille des embeddings\n",
    "    \"num_layers\": 3,         # Nombre de couches dans l'encodeur\n",
    "    \"use_batchnorm\": False,\n",
    "    \"device\": device,\n",
    "    \"seed\": 41\n",
    "}\n",
    "\n",
    "model = POMO_Agent(**hyper_params)\n",
    "network = model.qnetwork_local\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    coords = generate_instances(BATCH_SIZE, N_NODES, device)  # [B, N, 2]\n",
    "    B = coords.size(0)\n",
    "    \n",
    "    log_probs = []  # R√©initialiser √† chaque epoch\n",
    "    rewards = []    # R√©initialiser √† chaque epoch\n",
    "\n",
    "    for _ in range(POMO_SIZE):\n",
    "        mask = torch.zeros(B, N_NODES, device=device)  # Masque initial\n",
    "        tour = []\n",
    "        log_p = []\n",
    "        \n",
    "        for _ in range(N_NODES):\n",
    "            # Obtient les logits pour toutes les villes (masqu√©es si d√©j√† visit√©es)\n",
    "            logits = network(coords, mask)  # [B, N]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            \n",
    "            # √âchantillonne une action\n",
    "            m = torch.distributions.Categorical(probs)\n",
    "            action = m.sample()  # [B]\n",
    "            \n",
    "            # Met √† jour le masque et enregistre l'action\n",
    "            mask[torch.arange(B), action] = -float('inf')\n",
    "            tour.append(action)\n",
    "            log_p.append(m.log_prob(action))\n",
    "        \n",
    "        # Calcule la longueur du tour et les log-probs\n",
    "        tour = torch.stack(tour, dim=1)  # [B, N]\n",
    "        log_p = torch.stack(log_p, dim=1)  # [B, N]\n",
    "        \n",
    "        log_probs.append(log_p.sum(dim=1))  # [B]\n",
    "        rewards.append(compute_tour_length(coords, tour.unsqueeze(1)).squeeze(1))  # [B]\n",
    "\n",
    "    # Stack les r√©sultats pour POMO\n",
    "    log_probs = torch.stack(log_probs, dim=1)  # [B, P]\n",
    "    rewards = torch.stack(rewards, dim=1)      # [B, P]\n",
    "\n",
    "    # Calcul du POMO baseline et de la loss\n",
    "    baseline = rewards.mean(dim=1, keepdim=True)\n",
    "    advantage = baseline - rewards  # On veut minimiser la longueur\n",
    "    loss = (advantage.detach() * log_probs).mean()\n",
    "\n",
    "    # Backpropagation\n",
    "    model.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        avg_reward = rewards.min(dim=1)[0].mean().item()  # Meilleur tour par instance\n",
    "        print(f\"Epoch {epoch}, Avg reward: {avg_reward:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416d738",
   "metadata": {},
   "source": [
    "# Real POMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0fdb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import pickle\n",
    "from IPython import get_ipython\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bdcffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_train_steps 265435\n",
      "Agent pomo initialized\n",
      "POMO_Network(\n",
      "(encoder): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): ReLU()\n",
      "(2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): ReLU()\n",
      "(5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): ReLU()\n",
      "(8): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): ReLU()\n",
      "(11): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): ReLU()\n",
      "(14): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): ReLU()\n",
      "(17): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): ReLU()\n",
      "(20): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): ReLU()\n",
      "(23): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "(decoder): Linear(in_features=1024, out_features=80, bias=True)\n",
      ")\n",
      "Train mode\n",
      "Reward weights {'v_required': 0, 'v_sent': 0, 'v_sent_full': 0, 'v_degraded': 0, 'cancelled': 0, 'function_not_found': 0, 'v1_not_sent_from_s1': 0, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 0, 'rupture_ff': -100, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 0, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 0}\n",
      "constraint factor veh is  1\n",
      "constraint factor ff is  1 Number of ff: 3343\n",
      "Z_4 ['CADOURS', 'CARBONNE', 'CAZERES', 'ASPET', 'CINTEGABELLE', 'AURIGNAC', 'ISLE EN DODON', 'LE FOUSSERET', 'MONTESQUIEU VOLVESTRE', 'MONTREJEAU', 'REVEL', 'BAGNERES DE LUCHON', 'RIEUMES', 'RIEUX VOLVESTRE', 'SALIES DU SALAT', 'ST BEAT', 'ST GAUDENS', 'ST MARTORY', 'VILLEFRANCHE DE LAURAGAIS', 'VILLEMUR S/TARN', 'BOULOGNE SUR GESSE']\n",
      "df start-end 0 106173\n",
      "eps_start 1.0 eps_update 2308\n",
      "wandb: Currently logged in as: brandon-afonso3118 (brandon-afonso3118-university-of-toulouse) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in /home/brandon/Projet_TER/TEST_byMe/SVG_model/wandb/run-20250806_130905-kn0elf22\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run agent_pomo_1y_cfv1p1_rupture_ff\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff\n",
      "wandb: üöÄ View run at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/kn0elf22\n",
      "100 v_out: 11 | rwd_mean: 0.00 | v1notfroms1: 10 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 1\n",
      "100 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 8 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "200 v_out: 11 | rwd_mean: -2.00 | v1notfroms1: 12 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 2\n",
      "200 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 5 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "300 v_out: 5 | rwd_mean: 0.00 | v1notfroms1: 28 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 4\n",
      "300 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 9 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "400 v_out: 20 | rwd_mean: -6.00 | v1notfroms1: 63 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 7\n",
      "400 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 5 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "Traceback (most recent call last):\n",
      "File \"/home/brandon/Projet_TER/TEST_byMe/agent_run.py\", line 528, in <module>\n",
      "state = gen_state(veh_depart, idx_role, ff_array, ff_existing, \\\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/brandon/Projet_TER/TEST_byMe/collective_functions.py\", line 211, in gen_state\n",
      "state = np.hstack(([get_roles_for_ff(veh, ff_array, dic_roles, dic_roles_skills) for veh in veh_depart])).astype(float)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/brandon/Projet_TER/TEST_byMe/collective_functions.py\", line 470, in get_roles_for_ff\n",
      "return np.column_stack([get_role_from_skills(dic_roles_skills[role], ff_array).reshape(-1, 1) for role in required_roles])\n",
      "~~~~~~~~~~~~~~~~^^^^^^\n",
      "KeyError: 'CHEF DE GROUPE'\n",
      "\u001b[1;34mwandb\u001b[0m:\n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33magent_pomo_1y_cfv1p1_rupture_ff\u001b[0m at: \u001b[34mhttps://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/kn0elf22\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250806_130905-kn0elf22/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = \"pomo\"\n",
    "years = \"1y\"\n",
    "suffix = \"cfv1p1\"\n",
    "rwd=\"rupture_ff\"\n",
    "\n",
    "cmd = [\n",
    "    \"python3\", \"-u\", \"agent_run.py\",\n",
    "    \"--model_name\", f\"agent_{model}_{years}_{suffix}_{rwd}\",\n",
    "    \"--agent_model\", model,\n",
    "    \"--hyper_params\", \"hyper_params.json\",\n",
    "    \"--reward_weights\", f\"rw_{rwd}.json\",\n",
    "    \"--dataset\", f\"df_pc_fake_{years}.pkl\",\n",
    "    \"--start\", \"1\",\n",
    "    \"--end\", \"53088\",\n",
    "    \"--constraint_factor_veh\", \"1\",\n",
    "    \"--constraint_factor_ff\", \"1\",\n",
    "    \"--save_metrics_as\", f\"metrics_{model}_{years}_{suffix}_{rwd}\",\n",
    "    \"--train\",\n",
    "    \"--eps_start\",\"1\"\n",
    "\n",
    "]\n",
    "# \"--load\"\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "line_count = 0\n",
    "stdout_lines = deque(maxlen=5000)\n",
    "for line in process.stdout:\n",
    "    stdout_lines.append(line)\n",
    "    line_count += 1\n",
    "    if line_count % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe39c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*COD4*', 'COND_FMOGP', 'CA_ENG_SR', 'CA_VLD_RCH', 'CA_ENG_1EQUIPE', 'EQ_EPA', 'COND_ENG_PL_SD', 'EQ_ENG_INC', 'COND_VLHR', 'EQ_VSMP', 'CA_VLD', 'CA_VSMP', 'COND_EPA', 'COND_VGELD', '*CA_TE*', 'CA_VICH', 'CDS CODIS', 'EQ_ULTT', 'CA_ENG_INC', 'CA_CMIR', 'COND_PSECSAP', '*COD1*', 'COND_VPCE_DEPOL', '*CE*', 'COND_ENG_PL_TT', 'EQ_PSECINC', 'COND_VLA', 'COND_ENG_PL', 'COND_CEDEC', 'CA_FPT_RCH', '*CDC*', '*CDG*', 'EQ_VF', 'CA_VFT', 'CE_CEDEC', 'EQ_ENG_SR', 'COND_VL', 'EQ_VL', 'COND_FPT_RAD', 'EQ_CCF', 'COND_ULTT', '*CYN3*', 'CA_CEDEC', '*CYN2*', 'COND_VSR', 'COND_PCC', 'COND_VID', 'IMP_CU', 'COND_VFT', 'COND_PL_RCH', 'EQ_ENG_NAUT', 'CA_PSECSAP', 'CA_PSECINC', 'COND_VGREX', 'CA_ENG_INC_1EQ', 'CA_ENG_SAP', 'COND_CCFL500', 'EQ_VSSO', 'EQ_DIV', 'COND_ENG_PL2', 'COND_VSSO', 'COND_VSMP', 'COND_VGRIMP', 'EQ_ENG_SAP', 'CA_ENG_DIV', 'COND_BMS_EB', 'EQ_PSECSAP', 'COND_FPT_RCH', '*COD2*', 'EQ_CEDEC', 'CA_VSAV', 'COND_VF', 'COND_VPL', 'EQ_ENG_SAP2', 'COND_VLD', 'CA_FPT_RAD', '*COD6*', '*EQ*', 'CA_VPL', 'COND_CMIR', 'COND_CCF_FDF', 'CA_CCF', 'IMP_SAUV', 'COND_VLD_RCH', 'CA_RCH', 'EQ_VPL', 'CA_EPA', 'CE_ENG_INC', 'COND_VSAV', 'COND_VICH', 'CE_CCF']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "with open('./Data_environment/df_roles.pkl', 'rb') as f:\n",
    "    f = pickle.load(f)\n",
    "roles = list(set([_ for _ in f[\"Fonction\"]]))\n",
    "print(roles)\n",
    "print(\"CHEF DE GROUPE\" in roles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pompier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
