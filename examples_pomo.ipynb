{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1562a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import torch.optim as optim\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57302e2",
   "metadata": {},
   "source": [
    "# Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6308cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_utils_pomo import get_metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7ae70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "metrics = get_metrics(cur_path)\n",
    "os.chdir('./Reward_weights')\n",
    "for m in metrics:\n",
    "\n",
    "    dic_tarif_sent_disp = {'v_required': 0,\n",
    "                    'v_sent': 0,\n",
    "                    'v_sent_full':0,\n",
    "                    'v_degraded':0,\n",
    "                    'cancelled':0, #cancel departure\n",
    "                    'function_not_found':0,\n",
    "                    'v1_not_sent_from_s1':0,\n",
    "                    'v3_not_sent_from_s3':0,\n",
    "                    'v_not_found_in_last_station':0,\n",
    "                    'ff_required':0,\n",
    "                    'ff_sent':0,\n",
    "                    'rupture_ff':0,       \n",
    "                    'z1_VSAV_sent': 0,\n",
    "                    'z1_FPT_sent': 0,\n",
    "                    'z1_EPA_sent': 0,\n",
    "                     'VSAV_needed':0,\n",
    "                     'FPT_needed':0,\n",
    "                     'EPA_needed':0,\n",
    "                     'VSAV_disp':0,\n",
    "                     'FPT_disp':0,\n",
    "                     'EPA_disp':0,\n",
    "                    'skill_lvl':0\n",
    "                    } \n",
    "\n",
    "    dic_tarif_sent_disp[m] = -100\n",
    "\n",
    "    if m == 'v_degraded':\n",
    "        \n",
    "        dic_tarif_sent_disp['v_sent_full'] = 10\n",
    "\n",
    "\n",
    "    with open(f\"rw_\"+ m +\"_r100_cf3.json\", \"w\") as f:\n",
    "        json.dump(dic_tarif_sent_disp, f)\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22feeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_sent': 0,\n",
       " 'v_sent_full': 0,\n",
       " 'v_degraded': 0,\n",
       " 'cancelled': 0,\n",
       " 'function_not_found': 0,\n",
       " 'v1_not_sent_from_1st_station': -100,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'z1_sent': 0,\n",
       " 'skill_lvl': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v1_not_sent_from_1st_station\"\n",
    "with open(f\"rw_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6b63d",
   "metadata": {},
   "source": [
    "# Agent params POMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[0.93103448 1.         0.88888889 ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    file_path = f\"Reward_weights/rw_pomo_agent_{metric}_r100_cf3.json\"\n",
    "    try: os.remove(file_path)\n",
    "    except FileNotFoundError: print(f\"File '{file_path}' not found.\")\n",
    "print()\n",
    "\n",
    "#-------Start\n",
    "intervalle = 40\n",
    "start = 1\n",
    "\n",
    "while start <= 53080:\n",
    "    \n",
    "    end = start + intervalle - 1\n",
    "    if end > 53080: end = 53080\n",
    "    cmd = [\"python3\", \"-u\", \"agent_pomo_run.py\", \"--start\", str(start), \"--end\", str(end)]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        line_count += 1\n",
    "        #if line_count % 100 == 0:\n",
    "           #clear_output(wait=True)\n",
    "\n",
    "        print(line.strip())\n",
    "    \n",
    "    process.wait()\n",
    "    \n",
    "    start += intervalle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c50c41",
   "metadata": {},
   "source": [
    "I copy-pasted the output of previous block in the log.txt file so we can load this ipynb file in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[1.         1.         0.85185185 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.125      0.         0.5        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47fd99",
   "metadata": {},
   "source": [
    "# Reward  obtenu après itération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c4f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_required': 55,\n",
       " 'v_sent': 56,\n",
       " 'v_sent_full': 55,\n",
       " 'v_degraded': 1,\n",
       " 'rupture_ff': 6,\n",
       " 'function_not_found': 5,\n",
       " 'v1_not_sent_from_s1': 11,\n",
       " 'v3_not_sent_from_s3': 0,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'ff_required': 0,\n",
       " 'ff_sent': 200,\n",
       " 'z1_VSAV_sent': 0,\n",
       " 'z1_FPT_sent': 0,\n",
       " 'z1_EPA_sent': 0,\n",
       " 'VSAV_needed': 0,\n",
       " 'FPT_needed': 0,\n",
       " 'EPA_needed': 0,\n",
       " 'VSAV_disp': 8,\n",
       " 'FPT_disp': 0,\n",
       " 'EPA_disp': 0,\n",
       " 'skill_lvl': 331.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4244a",
   "metadata": {},
   "source": [
    "# Reward Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc623ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682.99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_mean_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875ee5e",
   "metadata": {},
   "source": [
    "# NEW version POMO test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbadab9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m coords = generate_instances(BATCH_SIZE, N_NODES, device)\n\u001b[32m     24\u001b[39m B = coords.size(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m node_embeds = \u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, N, H]\u001b[39;00m\n\u001b[32m     27\u001b[39m rewards = []\n\u001b[32m     28\u001b[39m log_probs = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "from agent import POMO_Agent\n",
    "\n",
    "def generate_instances(batch_size, n_nodes, device):\n",
    "    return torch.rand(batch_size, n_nodes, 2, device=device)\n",
    "\n",
    "def compute_tour_length(coords, tours):\n",
    "    # coords: [B, N, 2], tours: [B, pomo, N]\n",
    "    B, P, N = tours.size()\n",
    "    tour_coords = torch.gather(coords.unsqueeze(1).expand(-1, P, -1, -1), 2, tours.unsqueeze(-1).expand(-1, -1, -1, 2))\n",
    "    rolled = torch.roll(tour_coords, shifts=-1, dims=2)\n",
    "    lengths = ((tour_coords - rolled) ** 2).sum(dim=-1).sqrt().sum(dim=-1)  # [B, P]\n",
    "    return lengths\n",
    "\n",
    "N_EPOCHS = 200\n",
    "BATCH_SIZE = 256\n",
    "N_NODES = 80\n",
    "POMO_SIZE = 8\n",
    "\n",
    "hyper_params = {\"state_size\":3280, \"action_size\":80, \"layer_size\":1024, \"num_layers\":8, \"use_batchnorm\":0, \"device\":device, \"seed\":41}\n",
    "model = POMO_Agent(**hyper_params)\n",
    "network = model.network\n",
    "for epoch in range(N_EPOCHS):\n",
    "    coords = generate_instances(BATCH_SIZE, N_NODES, device)\n",
    "    B = coords.size(0)\n",
    "\n",
    "    node_embeds = network.encoder(coords)  # [B, N, H]\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    for _ in range(POMO_SIZE):\n",
    "        mask = torch.zeros(B, N_NODES, device=device)\n",
    "        tour = []\n",
    "        log_p = []\n",
    "        for _ in range(N_NODES):\n",
    "            probs = network(node_embeds, mask)\n",
    "            m = torch.distributions.Categorical(probs)\n",
    "            action = m.sample()\n",
    "            mask[torch.arange(B), action] = 1\n",
    "            tour.append(action)\n",
    "            log_p.append(m.log_prob(action))\n",
    "        tour = torch.stack(tour, dim=1)  # [B, N]\n",
    "        log_p = torch.stack(log_p, dim=1)  # [B, N]\n",
    "        log_probs.append(log_p.sum(dim=1))  # [B]\n",
    "        rewards.append(compute_tour_length(coords, tour.unsqueeze(1)).squeeze(1))  # [B]\n",
    "\n",
    "    log_probs = torch.stack(log_probs, dim=1)  # [B, P]\n",
    "    rewards = torch.stack(rewards, dim=1)  # [B, P]\n",
    "\n",
    "    # baseline POMO: moyenne sur chaque instance\n",
    "    baseline = rewards.mean(dim=1, keepdim=True)\n",
    "    advantage = baseline - rewards  # minimiser la distance => max(-length)\n",
    "    loss = (advantage.detach() * log_probs).mean()\n",
    "\n",
    "    model.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Avg reward: {rewards.min(dim=1)[0].mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pompier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
