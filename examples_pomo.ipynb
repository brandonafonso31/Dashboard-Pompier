{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57302e2",
   "metadata": {},
   "source": [
    "# Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff6308cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_utils_pomo import get_metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e7ae70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "metrics = get_metrics(cur_path)\n",
    "os.chdir('./Reward_weights')\n",
    "for m in metrics:\n",
    "\n",
    "    dic_tarif_sent_disp = {'v_required': 0,\n",
    "                    'v_sent': 0,\n",
    "                    'v_sent_full':0,\n",
    "                    'v_degraded':0,\n",
    "                    'cancelled':0, #cancel departure\n",
    "                    'function_not_found':0,\n",
    "                    'v1_not_sent_from_s1':0,\n",
    "                    'v3_not_sent_from_s3':0,\n",
    "                    'v_not_found_in_last_station':0,\n",
    "                    'ff_required':0,\n",
    "                    'ff_sent':0,\n",
    "                    'rupture_ff':0,       \n",
    "                    'z1_VSAV_sent': 0,\n",
    "                    'z1_FPT_sent': 0,\n",
    "                    'z1_EPA_sent': 0,\n",
    "                     'VSAV_needed':0,\n",
    "                     'FPT_needed':0,\n",
    "                     'EPA_needed':0,\n",
    "                     'VSAV_disp':0,\n",
    "                     'FPT_disp':0,\n",
    "                     'EPA_disp':0,\n",
    "                    'skill_lvl':0\n",
    "                    } \n",
    "\n",
    "    dic_tarif_sent_disp[m] = -100\n",
    "\n",
    "    if m == 'v_degraded':\n",
    "        \n",
    "        dic_tarif_sent_disp['v_sent_full'] = 10\n",
    "\n",
    "\n",
    "    with open(f\"rw_\"+ m +\"_r100_cf3.json\", \"w\") as f:\n",
    "        json.dump(dic_tarif_sent_disp, f)\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e22feeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_sent': 0,\n",
       " 'v_sent_full': 0,\n",
       " 'v_degraded': 0,\n",
       " 'cancelled': 0,\n",
       " 'function_not_found': 0,\n",
       " 'v1_not_sent_from_1st_station': -100,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'z1_sent': 0,\n",
       " 'skill_lvl': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v1_not_sent_from_1st_station\"\n",
    "with open(f\"rw_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6b63d",
   "metadata": {},
   "source": [
    "# Agent params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "025871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[0.92307692 0.72727273 1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf5bafab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Reward_weights/rw_pomo_agent_v3_not_sent_from_s3_r100_cf3.json' not found.\n",
      "File 'Reward_weights/rw_pomo_agent_v_not_found_in_last_station_r100_cf3.json' not found.\n",
      "File 'Reward_weights/rw_pomo_agent_z1_VSAV_sent_r100_cf3.json' not found.\n",
      "File 'Reward_weights/rw_pomo_agent_rupture_ff_r100_cf3.json' not found.\n",
      "\n",
      "Nombre d'agents = 2. On démarre...\n",
      "[RANDOM] Agent élu: v1_not_sent_from_s1\n",
      "[INFO] Fichier de reward de base chargé : rw_v1_not_sent_from_s1_r100_cf3.json\n",
      "[INFO] Fichier de reward de base chargé : rw_v_degraded_r100_cf3.json\n",
      "max_train_steps 195\n",
      "lr decay: 1 decay_update: 100 PER 1\n",
      "max_train_steps 195\n",
      "lr decay: 1 decay_update: 100 PER 1\n",
      "Dueling_QNetwork(\n",
      "(model): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(2): ReLU()\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(5): ReLU()\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(8): ReLU()\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(11): ReLU()\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(14): ReLU()\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(17): ReLU()\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(20): ReLU()\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(23): ReLU()\n",
      ")\n",
      "(ff_1_A): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(ff_1_V): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(bn_A): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(bn_V): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(advantage): Linear(in_features=1024, out_features=80, bias=True)\n",
      "(value): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "Agent dqn initialized\n",
      "Train mode\n",
      "Reward weights {'v_required': 0, 'v_sent': 0, 'v_sent_full': 10, 'v_degraded': -100, 'cancelled': 0, 'function_not_found': 0, 'v1_not_sent_from_s1': 0, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 0, 'rupture_ff': 0, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 0, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 0}\n",
      "constraint factor veh is  1\n",
      "constraint factor ff is  1 Number of ff: 3343\n",
      "Dueling_QNetwork(\n",
      "(model): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(2): ReLU()\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(5): ReLU()\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(8): ReLU()\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(11): ReLU()\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(14): ReLU()\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(17): ReLU()\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(20): ReLU()\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(23): ReLU()\n",
      ")\n",
      "(ff_1_A): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(ff_1_V): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(bn_A): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(bn_V): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(advantage): Linear(in_features=1024, out_features=80, bias=True)\n",
      "(value): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "Agent dqn initialized\n",
      "Train mode\n",
      "Reward weights {'v_required': 0, 'v_sent': 0, 'v_sent_full': 0, 'v_degraded': 0, 'cancelled': 0, 'function_not_found': 0, 'v1_not_sent_from_s1': -100, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 0, 'rupture_ff': 0, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 0, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 0}\n",
      "constraint factor veh is  1\n",
      "constraint factor ff is  1 Number of ff: 3343\n",
      "Z_4 ['CADOURS', 'CARBONNE', 'CAZERES', 'ASPET', 'CINTEGABELLE', 'AURIGNAC', 'ISLE EN DODON', 'LE FOUSSERET', 'MONTESQUIEU VOLVESTRE', 'MONTREJEAU', 'REVEL', 'BAGNERES DE LUCHON', 'RIEUMES', 'RIEUX VOLVESTRE', 'SALIES DU SALAT', 'ST BEAT', 'ST GAUDENS', 'ST MARTORY', 'VILLEFRANCHE DE LAURAGAIS', 'VILLEMUR S/TARN', 'BOULOGNE SUR GESSE']\n",
      "df start-end 0 84\n",
      "eps_start 1.0 eps_update 1\n",
      "Z_4 ['CADOURS', 'CARBONNE', 'CAZERES', 'ASPET', 'CINTEGABELLE', 'AURIGNAC', 'ISLE EN DODON', 'LE FOUSSERET', 'MONTESQUIEU VOLVESTRE', 'MONTREJEAU', 'REVEL', 'BAGNERES DE LUCHON', 'RIEUMES', 'RIEUX VOLVESTRE', 'SALIES DU SALAT', 'ST BEAT', 'ST GAUDENS', 'ST MARTORY', 'VILLEFRANCHE DE LAURAGAIS', 'VILLEMUR S/TARN', 'BOULOGNE SUR GESSE']\n",
      "df start-end 0 84\n",
      "eps_start 1.0 eps_update 1\n",
      "wandb: Currently logged in as: brandon-afonso3118 (brandon-afonso3118-university-of-toulouse) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Currently logged in as: brandon-afonso3118 (brandon-afonso3118-university-of-toulouse) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in /home/brandon/Projet_TER/TEST_byMe/SVG_model/wandb/run-20250728_142422-8m2aaf5s\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run pomo_agent_v_degraded\n",
      "wandb: ⭐️ View project at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff\n",
      "wandb: 🚀 View run at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/8m2aaf5s\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in /home/brandon/Projet_TER/TEST_byMe/SVG_model/wandb/run-20250728_142422-069um1m1\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run pomo_agent_v1_not_sent_from_s1\n",
      "wandb: ⭐️ View project at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff\n",
      "wandb: 🚀 View run at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/069um1m1\n",
      "\n",
      "Agent saved as pomo_agent_v_degraded\n",
      "rw_pomo_agent_v_degraded_r100_cf3.json enregistré\n",
      "rw_mean_pomo_agent_v_degraded_r100_cf3.json enregistré\n",
      "\n",
      "Agent saved as pomo_agent_v1_not_sent_from_s1\n",
      "rw_pomo_agent_v1_not_sent_from_s1_r100_cf3.json enregistré\n",
      "rw_mean_pomo_agent_v1_not_sent_from_s1_r100_cf3.json enregistré\n",
      "\u001b[1;34mwandb\u001b[0m:\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mpomo_agent_v1_not_sent_from_s1\u001b[0m at: \u001b[34mhttps://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/069um1m1\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250728_142422-069um1m1/logs\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m:\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mpomo_agent_v_degraded\u001b[0m at: \u001b[34mhttps://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/8m2aaf5s\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250728_142422-8m2aaf5s/logs\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "File \"/home/brandon/Projet_TER/TEST_byMe/agent_pomo_run.py\", line 95, in <module>\n",
      "dic = {metric[i]:None for i in range(num_agents)}\n",
      "^^^^^^\n",
      "NameError: name 'metric' is not defined. Did you mean: 'metrics'?\n",
      "Nombre d'agents = 2. On démarre...\n",
      "[RANDOM] Agent élu: v1_not_sent_from_s1\n",
      "[INFO] Fichier de reward précédemment entraîné chargé : rw_pomo_agent_v1_not_sent_from_s1_r100_cf3.json\n",
      "[INFO] Fichier de reward précédemment entraîné chargé : rw_pomo_agent_v_degraded_r100_cf3.json\n",
      "max_train_steps 195\n",
      "lr decay: 1 decay_update: 100 PER 1\n",
      "max_train_steps 195\n",
      "lr decay: 1 decay_update: 100 PER 1\n",
      "Dueling_QNetwork(\n",
      "(model): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(2): ReLU()\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(5): ReLU()\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(8): ReLU()\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(11): ReLU()\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(14): ReLU()\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(17): ReLU()\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(20): ReLU()\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(23): ReLU()\n",
      ")\n",
      "(ff_1_A): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(ff_1_V): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(bn_A): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(bn_V): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(advantage): Linear(in_features=1024, out_features=80, bias=True)\n",
      "(value): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "Agent dqn initialized\n",
      "Train mode\n",
      "Reward weights {'v_required': 54, 'v_sent': 54, 'v_sent_full': 54, 'v_degraded': 0, 'rupture_ff': 4, 'function_not_found': 4, 'v1_not_sent_from_s1': 8, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 204, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 4, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 334.0}\n",
      "Dueling_QNetwork(\n",
      "(model): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(2): ReLU()\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(5): ReLU()\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(8): ReLU()\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(11): ReLU()\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(14): ReLU()\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(17): ReLU()\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(20): ReLU()\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(23): ReLU()\n",
      ")\n",
      "(ff_1_A): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(ff_1_V): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(bn_A): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(bn_V): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(advantage): Linear(in_features=1024, out_features=80, bias=True)\n",
      "(value): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "Agent dqn initialized\n",
      "constraint factor veh is  1\n",
      "Train mode\n",
      "Reward weights {'v_required': 54, 'v_sent': 54, 'v_sent_full': 54, 'v_degraded': 0, 'rupture_ff': 4, 'function_not_found': 4, 'v1_not_sent_from_s1': 8, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 204, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 4, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 334.0}\n",
      "constraint factor ff is  1 Number of ff: 3343\n",
      "constraint factor veh is  1\n",
      "constraint factor ff is  1 Number of ff: 3343\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     17\u001b[39m process = subprocess.Popen(\n\u001b[32m     18\u001b[39m     cmd,\n\u001b[32m     19\u001b[39m     stdout=subprocess.PIPE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     bufsize=\u001b[32m1\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m line_count = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mline_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#if line_count % 100 == 0:\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m       \u001b[49m\u001b[38;5;66;43;03m#clear_output(wait=True)\u001b[39;49;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    file_path = f\"Reward_weights/rw_pomo_agent_{metric}_r100_cf3.json\"\n",
    "    try: os.remove(file_path)\n",
    "    except FileNotFoundError: print(f\"File '{file_path}' not found.\")\n",
    "print()\n",
    "\n",
    "#-------Start\n",
    "intervalle = 40\n",
    "start = 1\n",
    "\n",
    "while start <= 53080:\n",
    "    \n",
    "    end = start + intervalle - 1\n",
    "    if end > 53080: end = 53080\n",
    "    cmd = [\"python3\", \"-u\", \"agent_pomo_run.py\", \"--start\", str(start), \"--end\", str(end)]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        line_count += 1\n",
    "        #if line_count % 100 == 0:\n",
    "           #clear_output(wait=True)\n",
    "\n",
    "        print(line.strip())\n",
    "    \n",
    "    process.wait()\n",
    "    \n",
    "    start += intervalle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "File `'plot_evo.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/IPython/core/magics/execution.py:728\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    727\u001b[39m     fpath = arg_lst[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m     filename = \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/IPython/utils/path.py:90\u001b[39m, in \u001b[36mget_py_filename\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m` not found.\u001b[39m\u001b[33m\"\u001b[39m % name)\n",
      "\u001b[31mOSError\u001b[39m: File `'plot_evo.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m loss = compute_pomo_loss(all_rewards)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(all_rewards)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplot_evo.py agent_pomo_metrics_z1_sent_r100_cf3_train_reward_fake.npy --interpolation 100000\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2504\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2502\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2504\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2508\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/IPython/core/magics/execution.py:739\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re.match(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m$\u001b[39m\u001b[33m\"\u001b[39m,fpath):\n\u001b[32m    738\u001b[39m         warn(\u001b[33m'\u001b[39m\u001b[33mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33mun \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmyfile.py\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys.meta_path:\n",
      "\u001b[31mException\u001b[39m: File `'plot_evo.py'` not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_agent_rewards(metrics, num_agents=2):\n",
    "    \"\"\"Charge les récompenses de tous les agents depuis les fichiers .npy\"\"\"\n",
    "    all_rewards = []\n",
    "    for i in range(num_agents):\n",
    "        file_path = f\"Plots/agent_pomo_metrics_{metrics[i]}_r100_cf3_train_reward_fake.npy\"\n",
    "        if os.path.exists(file_path):\n",
    "            rewards = np.load(file_path)\n",
    "            all_rewards.append(rewards)\n",
    "    return np.array(all_rewards)\n",
    "\n",
    "def compute_pomo_loss(all_rewards):\n",
    "    \"\"\"Calcule la loss POMO avec baseline partagée\"\"\"\n",
    "    rewards_tensor = torch.tensor(all_rewards, dtype=torch.float32)\n",
    "    baseline = rewards_tensor.mean(dim=0, keepdim=True)\n",
    "    advantages = rewards_tensor - baseline\n",
    "    loss = -torch.mean(advantages * torch.log(rewards_tensor + 1e-10))\n",
    "    return loss\n",
    "\n",
    "metrics = ['z1_sent', 'v_not_found_in_last_station']\n",
    "num_agents = len(metrics)\n",
    "all_rewards = load_agent_rewards(metrics, num_agents)\n",
    "loss = compute_pomo_loss(all_rewards)\n",
    "\n",
    "print(all_rewards)\n",
    "\n",
    "%run plot_evo.py agent_pomo_metrics_z1_sent_r100_cf3_train_reward_fake.npy --interpolation 100000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pompier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
