{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1562a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import torch.optim as optim\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57302e2",
   "metadata": {},
   "source": [
    "# Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6308cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_utils_pomo import get_metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7ae70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "metrics = get_metrics(cur_path)\n",
    "os.chdir('./Reward_weights')\n",
    "for m in metrics:\n",
    "\n",
    "    dic_tarif_sent_disp = {'v_required': 0,\n",
    "                    'v_sent': 0,\n",
    "                    'v_sent_full':0,\n",
    "                    'v_degraded':0,\n",
    "                    'cancelled':0, #cancel departure\n",
    "                    'function_not_found':0,\n",
    "                    'v1_not_sent_from_s1':0,\n",
    "                    'v3_not_sent_from_s3':0,\n",
    "                    'v_not_found_in_last_station':0,\n",
    "                    'ff_required':0,\n",
    "                    'ff_sent':0,\n",
    "                    'rupture_ff':0,       \n",
    "                    'z1_VSAV_sent': 0,\n",
    "                    'z1_FPT_sent': 0,\n",
    "                    'z1_EPA_sent': 0,\n",
    "                     'VSAV_needed':0,\n",
    "                     'FPT_needed':0,\n",
    "                     'EPA_needed':0,\n",
    "                     'VSAV_disp':0,\n",
    "                     'FPT_disp':0,\n",
    "                     'EPA_disp':0,\n",
    "                    'skill_lvl':0\n",
    "                    } \n",
    "\n",
    "    dic_tarif_sent_disp[m] = -100\n",
    "\n",
    "    if m == 'v_degraded':\n",
    "        \n",
    "        dic_tarif_sent_disp['v_sent_full'] = 10\n",
    "\n",
    "\n",
    "    with open(f\"rw_\"+ m +\"_r100_cf3.json\", \"w\") as f:\n",
    "        json.dump(dic_tarif_sent_disp, f)\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22feeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_sent': 0,\n",
       " 'v_sent_full': 0,\n",
       " 'v_degraded': 0,\n",
       " 'cancelled': 0,\n",
       " 'function_not_found': 0,\n",
       " 'v1_not_sent_from_1st_station': -100,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'z1_sent': 0,\n",
       " 'skill_lvl': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v1_not_sent_from_1st_station\"\n",
    "with open(f\"rw_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6b63d",
   "metadata": {},
   "source": [
    "# Agent params POMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[0.93103448 1.         0.88888889 ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    file_path = f\"Reward_weights/rw_pomo_agent_{metric}_r100_cf3.json\"\n",
    "    try: os.remove(file_path)\n",
    "    except FileNotFoundError: print(f\"File '{file_path}' not found.\")\n",
    "print()\n",
    "\n",
    "#-------Start\n",
    "intervalle = 40\n",
    "start = 1\n",
    "\n",
    "while start <= 53080:\n",
    "    \n",
    "    end = start + intervalle - 1\n",
    "    if end > 53080: end = 53080\n",
    "    cmd = [\"python3\", \"-u\", \"agent_pomo_run.py\", \"--start\", str(start), \"--end\", str(end)]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        line_count += 1\n",
    "        #if line_count % 100 == 0:\n",
    "           #clear_output(wait=True)\n",
    "\n",
    "        print(line.strip())\n",
    "    \n",
    "    process.wait()\n",
    "    \n",
    "    start += intervalle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c50c41",
   "metadata": {},
   "source": [
    "I copy-pasted the output of previous block in the log.txt file so we can load this ipynb file in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "(82, 40)\n",
      "[[1.         1.         0.85185185 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.125      0.         0.5        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./SVG_model/shared_state_pomo.pt\"\n",
    "data = torch.load(path, map_location=device,weights_only=False)\n",
    "print(\"Type :\", type(data))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47fd99",
   "metadata": {},
   "source": [
    "# Reward  obtenu aprÃ¨s itÃ©ration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c4f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_required': 55,\n",
       " 'v_sent': 56,\n",
       " 'v_sent_full': 55,\n",
       " 'v_degraded': 1,\n",
       " 'rupture_ff': 6,\n",
       " 'function_not_found': 5,\n",
       " 'v1_not_sent_from_s1': 11,\n",
       " 'v3_not_sent_from_s3': 0,\n",
       " 'v_not_found_in_last_station': 0,\n",
       " 'ff_required': 0,\n",
       " 'ff_sent': 200,\n",
       " 'z1_VSAV_sent': 0,\n",
       " 'z1_FPT_sent': 0,\n",
       " 'z1_EPA_sent': 0,\n",
       " 'VSAV_needed': 0,\n",
       " 'FPT_needed': 0,\n",
       " 'EPA_needed': 0,\n",
       " 'VSAV_disp': 8,\n",
       " 'FPT_disp': 0,\n",
       " 'EPA_disp': 0,\n",
       " 'skill_lvl': 331.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4244a",
   "metadata": {},
   "source": [
    "# Reward Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc623ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682.99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Reward_weights')\n",
    "metric = \"v_degraded\"\n",
    "with open(f\"rw_mean_pomo_agent_{metric}_r100_cf3.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "os.chdir(\"../\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875ee5e",
   "metadata": {},
   "source": [
    "# NEW version POMO test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Avg reward: 39.7859\n",
      "Epoch 50, Avg reward: 41.7350\n",
      "Epoch 100, Avg reward: 52.0276\n",
      "Epoch 150, Avg reward: 50.0130\n"
     ]
    }
   ],
   "source": [
    "from agent import POMO_Agent\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def generate_instances(batch_size, n_nodes, device):\n",
    "    return torch.rand(batch_size, n_nodes, 2, device=device)\n",
    "\n",
    "def compute_tour_length(coords, tours):\n",
    "    B, P, N = tours.size()\n",
    "    tour_coords = torch.gather(coords.unsqueeze(1).expand(-1, P, -1, -1), 2, tours.unsqueeze(-1).expand(-1, -1, -1, 2))\n",
    "    rolled = torch.roll(tour_coords, shifts=-1, dims=2)\n",
    "    lengths = ((tour_coords - rolled) ** 2).sum(dim=-1).sqrt().sum(dim=-1)\n",
    "    return lengths\n",
    "\n",
    "N_EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "N_NODES = 80\n",
    "POMO_SIZE = 2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hyper_params = {\n",
    "    \"node_feature_size\": 2,  # (x,y)\n",
    "    \"hidden_size\": 64,      # Taille des embeddings\n",
    "    \"num_layers\": 3,         # Nombre de couches dans l'encodeur\n",
    "    \"use_batchnorm\": False,\n",
    "    \"device\": device,\n",
    "    \"seed\": 41\n",
    "}\n",
    "\n",
    "model = POMO_Agent(**hyper_params)\n",
    "network = model.qnetwork_local\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    coords = generate_instances(BATCH_SIZE, N_NODES, device)  # [B, N, 2]\n",
    "    B = coords.size(0)\n",
    "    \n",
    "    log_probs = []  # RÃ©initialiser Ã  chaque epoch\n",
    "    rewards = []    # RÃ©initialiser Ã  chaque epoch\n",
    "\n",
    "    for _ in range(POMO_SIZE):\n",
    "        mask = torch.zeros(B, N_NODES, device=device)  # Masque initial\n",
    "        tour = []\n",
    "        log_p = []\n",
    "        \n",
    "        for _ in range(N_NODES):\n",
    "            # Obtient les logits pour toutes les villes (masquÃ©es si dÃ©jÃ  visitÃ©es)\n",
    "            logits = network(coords, mask)  # [B, N]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Ã‰chantillonne une action\n",
    "            m = torch.distributions.Categorical(probs)\n",
    "            action = m.sample()  # [B]\n",
    "            \n",
    "            # Met Ã  jour le masque et enregistre l'action\n",
    "            mask[torch.arange(B), action] = -float('inf')\n",
    "            tour.append(action)\n",
    "            log_p.append(m.log_prob(action))\n",
    "        \n",
    "        # Calcule la longueur du tour et les log-probs\n",
    "        tour = torch.stack(tour, dim=1)  # [B, N]\n",
    "        log_p = torch.stack(log_p, dim=1)  # [B, N]\n",
    "        \n",
    "        log_probs.append(log_p.sum(dim=1))  # [B]\n",
    "        rewards.append(compute_tour_length(coords, tour.unsqueeze(1)).squeeze(1))  # [B]\n",
    "\n",
    "    # Stack les rÃ©sultats pour POMO\n",
    "    log_probs = torch.stack(log_probs, dim=1)  # [B, P]\n",
    "    rewards = torch.stack(rewards, dim=1)      # [B, P]\n",
    "\n",
    "    # Calcul du POMO baseline et de la loss\n",
    "    baseline = rewards.mean(dim=1, keepdim=True)\n",
    "    advantage = baseline - rewards  # On veut minimiser la longueur\n",
    "    loss = (advantage.detach() * log_probs).mean()\n",
    "\n",
    "    # Backpropagation\n",
    "    model.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        avg_reward = rewards.min(dim=1)[0].mean().item()  # Meilleur tour par instance\n",
    "        print(f\"Epoch {epoch}, Avg reward: {avg_reward:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416d738",
   "metadata": {},
   "source": [
    "# Real POMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0fdb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/Projet_TER/TEST_byMe/env_pompier/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import pickle\n",
    "from IPython import get_ipython\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_train_steps 265435\n",
      "Agent pomo initialized\n",
      "POMO_Network(\n",
      "(encoder): Sequential(\n",
      "(0): Linear(in_features=3280, out_features=1024, bias=True)\n",
      "(1): ReLU()\n",
      "(2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(4): ReLU()\n",
      "(5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(7): ReLU()\n",
      "(8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(10): ReLU()\n",
      "(11): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(13): ReLU()\n",
      "(14): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(16): ReLU()\n",
      "(17): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(19): ReLU()\n",
      "(20): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "(21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "(22): ReLU()\n",
      "(23): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "(decoder): Linear(in_features=1024, out_features=80, bias=True)\n",
      ")\n",
      "Train mode\n",
      "Reward weights {'v_required': 0, 'v_sent': 0, 'v_sent_full': 0, 'v_degraded': 0, 'cancelled': 0, 'function_not_found': 0, 'v1_not_sent_from_s1': 0, 'v3_not_sent_from_s3': 0, 'v_not_found_in_last_station': 0, 'ff_required': 0, 'ff_sent': 0, 'rupture_ff': -100, 'z1_VSAV_sent': 0, 'z1_FPT_sent': 0, 'z1_EPA_sent': 0, 'VSAV_needed': 0, 'FPT_needed': 0, 'EPA_needed': 0, 'VSAV_disp': 0, 'FPT_disp': 0, 'EPA_disp': 0, 'skill_lvl': 0}\n",
      "constraint factor veh is  1\n",
      "constraint factor ff is  1 Number of ff: 3343\n",
      "Z_4 ['CADOURS', 'CARBONNE', 'CAZERES', 'ASPET', 'CINTEGABELLE', 'AURIGNAC', 'ISLE EN DODON', 'LE FOUSSERET', 'MONTESQUIEU VOLVESTRE', 'MONTREJEAU', 'REVEL', 'BAGNERES DE LUCHON', 'RIEUMES', 'RIEUX VOLVESTRE', 'SALIES DU SALAT', 'ST BEAT', 'ST GAUDENS', 'ST MARTORY', 'VILLEFRANCHE DE LAURAGAIS', 'VILLEMUR S/TARN', 'BOULOGNE SUR GESSE']\n",
      "df start-end 0 106173\n",
      "eps_start 1.0 eps_update 2308\n",
      "wandb: Currently logged in as: brandon-afonso3118 (brandon-afonso3118-university-of-toulouse) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in /home/brandon/Projet_TER/TEST_byMe/SVG_model/wandb/run-20250806_160726-9anibx2g\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run agent_pomo_1y_cfv1p1_rupture_ff\n",
      "wandb: â­ï¸ View project at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff\n",
      "wandb: ðŸš€ View run at https://wandb.ai/brandon-afonso3118-university-of-toulouse/simu_ff/runs/9anibx2g\n",
      "100 v_out: 11 | rwd_mean: 0.00 | v1notfroms1: 9 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 0\n",
      "100 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 8 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "200 v_out: 11 | rwd_mean: -2.00 | v1notfroms1: 11 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 1\n",
      "200 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 5 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "300 v_out: 5 | rwd_mean: 0.00 | v1notfroms1: 28 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 1\n",
      "300 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 9 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "400 v_out: 20 | rwd_mean: -5.00 | v1notfroms1: 73 | v3notfroms3: 0 | v_not_found_ls: 0 | deg: 8\n",
      "400 z1_VSAV_sent: 0 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 4 | FPT_disp: 0 | EPA_disp: 0 |\n",
      "500 v_out: 11 | rwd_mean: -3.00 | v1notfroms1: 128 | v3notfroms3: 1 | v_not_found_ls: 0 | deg: 13\n",
      "500 z1_VSAV_sent: 2 | z1_FPT_sent: 0 | z1_EPA_sent: 0 | VSAV_disp: 7 | FPT_disp: 5 | EPA_disp: 0 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m line_count = \u001b[32m0\u001b[39m\n\u001b[32m     33\u001b[39m stdout_lines = deque(maxlen=\u001b[32m5000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstdout_lines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mline_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = \"pomo\"\n",
    "years = \"1y\"\n",
    "suffix = \"cfv1p1\"\n",
    "rwd=\"rupture_ff\"\n",
    "\n",
    "cmd = [\n",
    "    \"python3\", \"-u\", \"agent_run.py\",\n",
    "    \"--model_name\", f\"agent_{model}_{years}_{suffix}_{rwd}\",\n",
    "    \"--agent_model\", model,\n",
    "    \"--hyper_params\", \"hyper_params.json\",\n",
    "    \"--reward_weights\", f\"rw_{rwd}.json\",\n",
    "    \"--dataset\", f\"df_pc_fake_{years}.pkl\",\n",
    "    \"--start\", \"1\",\n",
    "    \"--end\", \"500\",\n",
    "    \"--constraint_factor_veh\", \"1\",\n",
    "    \"--constraint_factor_ff\", \"1\",\n",
    "    \"--save_metrics_as\", f\"metrics_{model}_{years}_{suffix}_{rwd}\",\n",
    "    \"--train\",\n",
    "    \"--eps_start\",\"1\"\n",
    "\n",
    "]\n",
    "# \"--end\", \"53088\",\n",
    "# \"--load\"\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "line_count = 0\n",
    "stdout_lines = deque(maxlen=5000)\n",
    "for line in process.stdout:\n",
    "    stdout_lines.append(line)\n",
    "    line_count += 1\n",
    "    if line_count % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(line.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pompier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
